{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3817f7c9",
   "metadata": {},
   "source": [
    "# Day 3 – Model Training: Naive Bayes vs. LSTM\n",
    "\n",
    "**Goal:** Train and evaluate both traditional ML (Naive Bayes) and deep learning (LSTM) models on cleaned product review data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e47ea",
   "metadata": {},
   "source": [
    "## Load Cleaned Data\n",
    "\n",
    "We’ll use the output from Day 2 (`cleaned_reviews.json`) and convert sentiment scores into categories:\n",
    "- 1, 2 → Negative (0)\n",
    "- 3 → Neutral (1)\n",
    "- 4, 5 → Positive (2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adc7044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I buy several vitality dog food product find g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived label jumbo salt peanutsthe pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look secret ingredient robitussin I believe I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  label\n",
       "0  I buy several vitality dog food product find g...      2\n",
       "1  product arrived label jumbo salt peanutsthe pe...      0\n",
       "2  confection around century light pillowy citrus...      2\n",
       "3  look secret ingredient robitussin I believe I ...      0\n",
       "4  great taffy great price wide assortment yummy ...      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/cleaned_reviews.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def map_sentiment(score):\n",
    "    if score <= 2:\n",
    "        return 0  # Negative\n",
    "    elif score == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 2  # Positive\n",
    "\n",
    "df['label'] = df['Score'].apply(map_sentiment)\n",
    "df = df[['clean_text', 'label']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983eaa77",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "\n",
    "We’ll split into 80% training and 20% testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e6a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b26f5a",
   "metadata": {},
   "source": [
    "## Naive Bayes Model (TF-IDF)\n",
    "\n",
    "We’ll use `TfidfVectorizer` to convert text into features and train a `MultinomialNB` classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.7513976824256305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.24      0.37     16407\n",
      "           1       0.62      0.00      0.00      8528\n",
      "           2       0.81      1.00      0.89     88756\n",
      "\n",
      "    accuracy                           0.81    113691\n",
      "   macro avg       0.76      0.41      0.42    113691\n",
      "weighted avg       0.80      0.81      0.75    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "print(\"Naive Bayes F1 Score:\", f1_nb)\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774a6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/naive_bayes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nb_model, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29191211",
   "metadata": {},
   "source": [
    "## LSTM Model (Deep Learning)\n",
    "\n",
    "We’ll use Keras to build a simple LSTM model using tokenized sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d026ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_len = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302f006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nitis\\anaconda3\\envs\\sentiment-nlp\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m6396/6396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 85ms/step - accuracy: 0.7890 - loss: 0.6332 - val_accuracy: 0.8595 - val_loss: 0.3941\n",
      "Epoch 2/5\n",
      "\u001b[1m6396/6396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 81ms/step - accuracy: 0.8616 - loss: 0.3856 - val_accuracy: 0.8753 - val_loss: 0.3404\n",
      "Epoch 3/5\n",
      "\u001b[1m6396/6396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 90ms/step - accuracy: 0.8818 - loss: 0.3245 - val_accuracy: 0.8833 - val_loss: 0.3236\n",
      "Epoch 4/5\n",
      "\u001b[1m6396/6396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 93ms/step - accuracy: 0.8932 - loss: 0.2941 - val_accuracy: 0.8862 - val_loss: 0.3180\n",
      "Epoch 5/5\n",
      "\u001b[1m6396/6396\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 97ms/step - accuracy: 0.9021 - loss: 0.2715 - val_accuracy: 0.8893 - val_loss: 0.3145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2692083fa30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=64, input_length=max_len))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.1, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79ab8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 19ms/step\n",
      "LSTM F1 Score: 0.8795013777398348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76     16407\n",
      "           1       0.60      0.34      0.43      8528\n",
      "           2       0.93      0.96      0.94     88756\n",
      "\n",
      "    accuracy                           0.89    113691\n",
      "   macro avg       0.76      0.69      0.71    113691\n",
      "weighted avg       0.88      0.89      0.88    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lstm = model.predict(X_test_pad)\n",
    "y_pred_lstm_final = np.argmax(y_pred_lstm, axis=1)\n",
    "\n",
    "f1_lstm = f1_score(y_test, y_pred_lstm_final, average='weighted')\n",
    "print(\"LSTM F1 Score:\", f1_lstm)\n",
    "print(classification_report(y_test, y_pred_lstm_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f135eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb76c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Naive Bayes    LSTM\n",
      "0       0.7514  0.8795\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"Naive Bayes\": round(f1_nb, 4),\n",
    "    \"LSTM\": round(f1_lstm, 4)\n",
    "}\n",
    "\n",
    "df_result = pd.DataFrame([results])\n",
    "df_result.to_csv(\"../results/f1_scores.csv\", index=False)\n",
    "\n",
    "print(df_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672563f3",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "- Trained Naive Bayes with TF-IDF features.\n",
    "- Built an LSTM model with embeddings and sequences.\n",
    "- Saved both models and logged F1-scores in `results/f1_scores.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63542bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
